{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Pobiernaie Danych"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "635cb70f3957044b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchWindowException\n",
    "\n",
    "# Sleep time\n",
    "WAIT_TIME = 10\n",
    "OUTPUT_DIRECTORY = 'data1/raw'\n",
    "\n",
    "# Połaczenie ze stroną noflufjobs\n",
    "def get_page_html(job_name, page_number):\n",
    "    try:\n",
    "        url = f'https://nofluffjobs.com/pl/jobs?criteria={job_name}&page={page_number}'\n",
    "        driver = webdriver.Chrome()\n",
    "        driver.get(url)\n",
    "\n",
    "        time.sleep(WAIT_TIME)\n",
    "\n",
    "        page_html = driver.page_source\n",
    "        driver.quit()\n",
    "        return page_html\n",
    "    except NoSuchWindowException:\n",
    "        print(\"Okno przeglądarki zostało zamknięte.\")\n",
    "        return None\n",
    "\n",
    "# Sprawdzenie stron\n",
    "def has_more_jobs_in_page(page_html):\n",
    "    soup = BeautifulSoup(page_html, 'html.parser')\n",
    "    next_page_link = soup.find('a', class_='page-link', text='»')\n",
    "    return next_page_link is not None\n",
    "\n",
    "# Zapis strony\n",
    "def save_page_to_file(job_name, page_number, page_html):\n",
    "    filename = os.path.join(OUTPUT_DIRECTORY, f'{job_name}_{page_number}.html')\n",
    "    with open(filename, 'w', encoding='utf-8') as file:\n",
    "        file.write(page_html)\n",
    "\n",
    "# Prasowanie nazwy pliku\n",
    "def extract_job_names(page_html):\n",
    "    soup = BeautifulSoup(page_html, 'html.parser')\n",
    "    job_names = []\n",
    "\n",
    "    job_name_elements = soup.find_all('h3', class_='posting-title__position')\n",
    "    for element in job_name_elements:\n",
    "        job_name = element.text.strip()\n",
    "        job_names.append(job_name)\n",
    "\n",
    "    return job_names\n",
    "\n",
    "# Wtświetlenie ofert\n",
    "def display_job_info(job_name, page_number, job_names_on_page):\n",
    "    print(f\"Stanowisko: {job_name}\")\n",
    "    print(f\"Numer strony: {page_number}\")\n",
    "    print(\"Oferty na stronie:\")\n",
    "    for idx, job_name in enumerate(job_names_on_page, start=1):\n",
    "        print(f\"{idx}. {job_name}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Wybór ofert\n",
    "def scrape_jobs():\n",
    "    job_names = input(\"Podaj oferty pracy (oddzielone przecinkami): \").split(',')\n",
    "    for job_name in job_names:\n",
    "        page_number = 1\n",
    "        while True:\n",
    "            page_html = get_page_html(job_name, page_number)\n",
    "            if page_html is None:\n",
    "                break\n",
    "            save_page_to_file(job_name, page_number, page_html)\n",
    "            job_names_on_page = extract_job_names(page_html)\n",
    "            if not job_names_on_page:\n",
    "                print(f\"Brak ofert dla stanowiska: {job_name}. Przechodzę do następnego stanowiska.\")\n",
    "                break\n",
    "            display_job_info(job_name, page_number, job_names_on_page)\n",
    "            page_number += 1\n",
    "            time.sleep(5)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    scrape_jobs()\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-02-04T22:00:34.725594200Z"
    }
   },
   "id": "1b34de7fc4fdf7d7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Scrapowanie danych - Plik"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8af385ddba6aa3f9"
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dane zapisano do pliku: interim\\job_data_2024-02-04.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "from datetime import date\n",
    "\n",
    "# Funkcja pobierająca dane z kodu HTML (pobrane oferty) \n",
    "def extract_job_info(html_code, file_name):\n",
    "    soup = BeautifulSoup(html_code, 'html.parser')\n",
    "    job_blocks = soup.find_all('a', class_='posting-list-item')\n",
    "\n",
    "    job_info_list = []\n",
    "    for job_block in job_blocks:\n",
    "        job_info = {}\n",
    "        \n",
    "        # Dodajemy nazwę pliku bez rozszerzenia\n",
    "        job_info['file_name'] = file_name\n",
    "\n",
    "        # Nazwa stanowiksa\n",
    "        job_info['position_name'] = job_block.find('h3', class_='posting-title__position').text.strip()\n",
    "        \n",
    "        # Nazwa firmy\n",
    "        company_tag = job_block.find('h4', class_='tw-text-gray-60 company-name tw-w-[50%] lg:tw-w-auto tw-mb-0 !tw-text-xs !lg:tw-text-sm tw-font-semibold lg:tw-font-normal')\n",
    "        if company_tag and company_tag.text.strip():\n",
    "            job_info['company'] = company_tag.text.strip()\n",
    "        else:\n",
    "            job_info['company'] = 'Nie znaleziono nazwy firmy'\n",
    "\n",
    "        # Informacje oferty  \n",
    "        offer_technology_info = job_block.find('span', class_='lg:tw-text-gray-60 lg:tw-border-2 lg:tw-border-gray-ddd tw-text-xs tw-lowercase lg:tw-py-0.5 lg:tw-px-2 tw-text-gray-60')\n",
    "        if offer_technology_info and offer_technology_info.text.strip():\n",
    "            job_info['job_information'] = offer_technology_info.text.strip()\n",
    "        else:\n",
    "            job_info['job_information'] = 'No Data'\n",
    "\n",
    "        # Widełki (wynagrodzenie)\n",
    "        salary = job_block.find('span', class_='text-truncate badgy salary lg:tw-btn tw-text-ink lg:tw-btn-secondary-outline tw-text-xs lg:tw-py-0.5 lg:tw-px-2 ng-star-inserted')\n",
    "        if salary and salary.text.strip():\n",
    "            low, high = parse_salary_info(salary.text.strip())\n",
    "            job_info['salary_low'] = low\n",
    "            job_info['salary_high'] = high\n",
    "            job_info['currency'] = 'PLN'\n",
    "        else:\n",
    "            job_info['salary_low'] = 'N/A'\n",
    "            job_info['salary_high'] = 'N/A'\n",
    "            job_info['currency'] = 'N/A'\n",
    "\n",
    "        # Lokalizacja\n",
    "        location_info = job_block.find('span', class_='tw-text-ellipsis tw-inline-block tw-overflow-hidden tw-whitespace-nowrap tw-max-w-[100px] md:tw-max-w-[200px] tw-text-right')\n",
    "        if location_info and location_info.text.strip():\n",
    "            job_info['location'] = location_info.text.strip()\n",
    "        else:\n",
    "            job_info['location'] = 'No Data'\n",
    "\n",
    "        job_info_list.append(job_info)\n",
    "\n",
    "    return job_info_list\n",
    "\n",
    "# Funkcja parsująca informacje o wynagrodzeniu\n",
    "def parse_salary_info(salary):\n",
    "    cleaned_salary_info = ''.join(salary.split())\n",
    "    parts = cleaned_salary_info.split(\"–\")\n",
    "    if len(parts) == 2:\n",
    "        low = int(''.join(filter(str.isdigit, parts[0])))\n",
    "        high = int(''.join(filter(str.isdigit, parts[1])))\n",
    "        return low, high\n",
    "    else:\n",
    "        return 'N/A', 'N/A'\n",
    "\n",
    "def main():\n",
    "    # Ścieżka przechowująca pliki html\n",
    "    raw_data_directory = 'data1/raw/'\n",
    "\n",
    "    job_data = []  \n",
    "\n",
    "    for filename in os.listdir(raw_data_directory):\n",
    "        if filename.endswith('.html'):\n",
    "            filepath = os.path.join(raw_data_directory, filename)\n",
    "            \n",
    "            \n",
    "            file_name = os.path.splitext(filename)[0]\n",
    "            \n",
    "            with open(filepath, 'r', encoding='utf-8') as file:\n",
    "                html_code = file.read()\n",
    "\n",
    "            job_info_list = extract_job_info(html_code, file_name)\n",
    "\n",
    "            if job_info_list:\n",
    "                job_data.extend(job_info_list)\n",
    "\n",
    "    if job_data:\n",
    "        # Ścieżka zapisu pliku\n",
    "        today = date.today()\n",
    "        output_directory = 'interim'\n",
    "        if not os.path.exists(output_directory):\n",
    "            os.makedirs(output_directory)\n",
    "        output_file = os.path.join(output_directory, f'job_data_{today}.csv')\n",
    "\n",
    "        # Zapis do pliku CSV \n",
    "        with open(output_file, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "            csv_writer = csv.DictWriter(csv_file, fieldnames=job_data[0].keys())\n",
    "            csv_writer.writeheader()\n",
    "            csv_writer.writerows(job_data)\n",
    "\n",
    "        print(f\"Dane zapisano do pliku: {output_file}\")\n",
    "    else:\n",
    "        print(\"Brak ofert pracy.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T21:57:23.653846400Z",
     "start_time": "2024-02-04T21:57:15.526494Z"
    }
   },
   "id": "caeb7e8f6ba71872"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Transformacja danych "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b0c8f095e20c0ecc"
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Przetworzone dane zapisano do pliku: processed/job_offers_2024-02-04.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def clean_and_save_csv(input_file, output_dir):\n",
    "\n",
    "    df = pd.read_csv(input_file)\n",
    "   \n",
    " \n",
    "    # Wyliczenie średniej pensji stanowiska\n",
    "    if 'salary_high' in df.columns and 'salary_low' in df.columns:\n",
    "        df['salary_avg'] = (df['salary_high'] + df['salary_low']) / 2\n",
    "    else:\n",
    "        df['salary_avg'] = 'N/A'\n",
    "        \n",
    "    # Poziom Stanowiska\n",
    "    df['is_senior'] = df['position_name'].str.contains('senior', case=False).astype(int)\n",
    "    df['is_lead'] = df['position_name'].str.contains('lead', case=False).astype(int)\n",
    "    df['is_mid'] = df['position_name'].str.contains('mid', case=False).astype(int)\n",
    "    df['is_junior'] = df['position_name'].str.contains('junior', case=False).astype(int)\n",
    "    \n",
    "    # Zapis pliku z datą \n",
    "    today = pd.to_datetime('today').strftime('%Y-%m-%d')\n",
    "    output_file = f'{output_dir}/job_offers_{today}.csv'\n",
    "    df.to_csv(output_file, sep=';', encoding='utf-8', index=False)\n",
    "    print(f\"Przetworzone dane zapisano do pliku: {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_csv_file = 'interim/job_data_2024-02-04.csv'\n",
    "    output_directory = 'processed'\n",
    "\n",
    "    clean_and_save_csv(input_csv_file, output_directory)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T20:33:17.427643100Z",
     "start_time": "2024-02-04T20:33:17.368237900Z"
    }
   },
   "id": "bbd40bd6d404bb4f"
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dane zapisano do pliku: interim\\job_data_2024-02-04.csv\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T20:29:59.160780500Z",
     "start_time": "2024-02-04T20:29:50.913494400Z"
    }
   },
   "id": "67fd3d87e915d28d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "56fd269f61330d98"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
